{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMd9UcIJ77HV",
        "outputId": "7898def4-7a0a-4e3e-cf5d-8454be7b389d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/humairmunir/stories?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.09M/2.09M [00:00<00:00, 2.57MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/humairmunir/stories/versions/1\n",
            "Loading stories...\n",
            "Enter a starting word: was\n",
            "Generated text: was coming. She taught along the earth. As she failed? What do indeed,” she heard whispers of life—writers, artists, meant\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Download the dataset from KaggleHub\n",
        "dataset_path = kagglehub.dataset_download(\"humairmunir/stories\")\n",
        "print(\"Path to dataset files:\", dataset_path)\n",
        "\n",
        "# Function to load all .txt stories from the dataset\n",
        "def load_stories_from_directory(directory):\n",
        "    stories = \"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(directory, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "                stories += file.read() + \" \"\n",
        "    return stories\n",
        "\n",
        "# Function to create bigrams\n",
        "def create_bigrams(text):\n",
        "    words = text.split()\n",
        "    bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
        "    return bigrams\n",
        "\n",
        "# Function to build the bigram model\n",
        "def build_bigram_model(bigrams):\n",
        "    model = defaultdict(list)\n",
        "    for first, second in bigrams:\n",
        "        model[first].append(second)\n",
        "    return model\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(model, start_word, length=20):\n",
        "    current_word = start_word\n",
        "    generated_text = [current_word]\n",
        "    for _ in range(length - 1):\n",
        "        if current_word in model:\n",
        "            next_word = random.choice(model[current_word])\n",
        "            generated_text.append(next_word)\n",
        "            current_word = next_word\n",
        "        else:\n",
        "            break\n",
        "    return ' '.join(generated_text)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    print(\"Loading stories...\")\n",
        "    combined_story = load_stories_from_directory(dataset_path)\n",
        "    bigrams = create_bigrams(combined_story)\n",
        "    model = build_bigram_model(bigrams)\n",
        "\n",
        "    start_word = input(\"Enter a starting word: \")\n",
        "    if start_word in model:\n",
        "        generated_text = generate_text(model, start_word)\n",
        "        print(\"Generated text:\", generated_text)\n",
        "    else:\n",
        "        print(f\"The word '{start_word}' is not found in the corpus.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}